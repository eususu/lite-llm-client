# lite llm client

This project made for very light llm client.
the main idea is `do not use llm client library`.

# Roadmap

- [x] `2024-07-21` support OpenAI
- [x] `2024-07-25` support Anthropic
- [x] `2024-07-27` add options for inference
- [x] `2024-07-28` support Gemini
- [ ] support streming (OpenAI)
- [ ] support streming (Gemini)
- [ ] support streming (Anthropic)
- [ ] support multimodal (image and text)